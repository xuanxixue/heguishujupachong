# AI数据采集浏览器

![Python Version](https://img.shields.io/badge/Python-3.11-blue.svg)
![License](https://img.shields.io/badge/License-GPL--3.0-green.svg)
![Platform](https://img.shields.io/badge/Platform-Windows%20%7C%20Linux%20%7C%20macOS-lightgrey.svg)

## 📖 项目概述

**道衍AI浏览器 - 智能合规爬虫版**是一款集成了现代网页浏览、智能数据爬取、下载管理、历史记录和书签管理功能的综合性浏览器工具。该软件专为AI训练数据收集、学术研究、内容分析和日常网页浏览等场景设计，提供了直观的图形界面和强大的数据处理能力。

### 🧠 概念提出者
**张悦-玄曦雪**

### 💻 代码制作者
**Deepseek AI**

---

## ✨ 核心功能

### 🌐 现代化浏览器
- **多标签页浏览**：支持同时打开多个网页
- **完整导航功能**：前进、后退、刷新、主页
- **智能地址栏**：自动识别网址和搜索关键词
- **页面缩放**：支持页面放大、缩小和重置
- **新窗口支持**：完美处理需要新标签页打开的网站

### 🕷️ 智能数据爬取
- **合规性检查**：自动检查robots.txt，确保爬取合规性
- **双重爬取引擎**：
  - Requests库：快速爬取静态页面
  - Selenium：处理JavaScript渲染的动态页面（可选）
- **智能内容提取**：自动提取标题、正文、链接等关键信息
- **数据清洗**：移除无关标签，提取纯净文本内容

### 📥 完整的下载管理系统
- **下载管理器**：实时监控下载进度和状态
- **下载控制**：支持暂停、继续、取消下载
- **智能保存**：可选择下载前询问或自动保存
- **进度显示**：实时显示下载速度、剩余时间

### 📚 浏览历史管理
- **完整历史记录**：自动记录所有访问的网页
- **搜索功能**：按标题或URL搜索历史记录
- **快速访问**：双击历史记录项直接打开
- **清理功能**：支持清空历史记录

### 🔖 书签管理
- **添加书签**：一键保存当前页面到书签
- **书签管理器**：管理所有保存的书签
- **导入导出**：支持书签的导入和导出
- **快速访问**：双击书签项直接打开

### 💾 多格式数据导出
- **JSON格式**：结构化数据，便于程序处理
- **纯文本格式**：专为AI训练优化的格式
- **DOCX文档**：专业的Word文档格式（需要python-docx）
- **自动保存**：爬取数据实时保存，防止丢失

### ⚙️ 完整的设置系统
- **下载设置**：配置下载路径和下载行为
- **隐私设置**：控制JavaScript、图片加载等选项
- **浏览器行为**：自定义各种浏览器设置

### 🎨 现代化界面
- **清新设计**：现代化的用户界面设计
- **分割布局**：左侧浏览器，右侧数据管理面板
- **响应式设计**：支持窗口调整和布局优化
- **状态反馈**：实时状态信息和进度显示

---

## 🛠️ 技术架构

### 核心技术栈
- **前端界面**：PyQt5 + QtWebEngine
- **爬虫引擎**：Requests + BeautifulSoup4 + Selenium（可选）
- **浏览器内核**：Chromium (QtWebEngine)
- **文档处理**：python-docx（可选）
- **浏览器驱动**：ChromeDriver（可选）

### 系统要求
- **操作系统**：Windows 10/11, Linux, macOS
- **Python版本**：3.11+
- **内存**：4GB RAM（推荐8GB）
- **存储空间**：500MB可用空间

---

## 📥 安装指南

### 前置要求
1. 安装Python 3.11或更高版本
2. 安装Google Chrome浏览器（用于Selenium功能）

### 安装步骤

#### 1. 下载项目
```bash
# 克隆项目或直接下载源代码
git clone <项目地址>
# 或直接下载ZIP文件并解压
```

#### 2. 安装Python依赖
```bash
# 基础依赖（必需）
pip install PyQt5 PyQtWebEngine requests beautifulsoup4 lxml

# 高级功能依赖（可选但推荐）
pip install selenium webdriver-manager python-docx
```

#### 3. 运行程序
```bash
python liulanqi.py
```

### 可选配置
- **自定义输出目录**：修改代码中的`output_dir`参数
- **下载路径设置**：在设置中配置默认下载文件夹
- **用户代理**：可自定义浏览器用户代理字符串

---

## 🚀 使用说明

### 基本操作流程

1. **启动程序**
   - 运行`python liulanqi.py`
   - 程序自动初始化浏览器和所有组件

2. **浏览网页**
   - 在地址栏输入网址或搜索关键词
   - 使用导航按钮进行前进、后退、刷新操作
   - 使用快捷键快速操作（Ctrl+T新建标签页等）

3. **管理标签页**
   - 点击"+"按钮新建标签页
   - 点击标签页上的"×"关闭标签页
   - 使用Ctrl+Tab切换标签页

4. **使用爬虫功能**
   - 浏览到目标网页
   - 点击"🕷️ 抓取当前页"按钮
   - 查看右侧数据面板中的爬取结果

5. **管理下载**
   - 点击"📥"按钮打开下载管理器
   - 查看下载进度和状态
   - 管理下载任务（暂停、继续、取消）

6. **查看历史记录**
   - 点击"📚"按钮打开历史记录管理器
   - 搜索和访问历史网页

7. **管理书签**
   - 点击"🔖"按钮打开书签管理器
   - 添加、删除、导入导出书签

8. **导出数据**
   - 在右侧数据面板选择导出格式：
     - **保存数据**：JSON格式
     - **导出训练集**：纯文本格式
     - **导出DOCX**：Word文档格式（如可用）

### 快捷键列表

| 功能 | 快捷键 |
|------|--------|
| 新建标签页 | Ctrl+T |
| 新建窗口 | Ctrl+N |
| 关闭标签页 | Ctrl+W |
| 下载管理器 | Ctrl+J |
| 历史记录 | Ctrl+H |
| 添加书签 | Ctrl+D |
| 书签管理器 | Ctrl+Shift+O |
| 设置 | Ctrl+, |
| 退出 | Ctrl+Q |
| 剪切 | Ctrl+X |
| 复制 | Ctrl+C |
| 粘贴 | Ctrl+V |
| 放大页面 | Ctrl++ |
| 缩小页面 | Ctrl+- |
| 重置缩放 | Ctrl+0 |

---

## 🔧 故障排除

### 常见问题

#### 1. 导入错误
**问题**：`ImportError: cannot import name ...`
**解决方案**：
- 确保安装了正确版本的PyQt5
- 检查Python版本兼容性
- 更新所有依赖包

#### 2. Selenium不可用
**问题**：动态页面无法爬取
**解决方案**：
- 安装Selenium：`pip install selenium webdriver-manager`
- 确保已安装Google Chrome浏览器
- 或使用静态爬取模式

#### 3. 网站无法正常跳转
**问题**：某些网站链接点击无响应
**解决方案**：
- 确保已启用JavaScript
- 检查网络连接
- 尝试使用其他用户代理

#### 4. 内存占用过高
**问题**：打开多个标签页后内存使用增加
**解决方案**：
- 关闭不需要的标签页
- 定期清理浏览器数据
- 增加系统虚拟内存

#### 5. 下载功能异常
**问题**：文件无法下载或下载失败
**解决方案**：
- 检查下载文件夹权限
- 确认磁盘空间充足
- 检查网络连接稳定性

### 调试模式
程序内置了详细的日志记录，如需调试：
1. 查看控制台输出信息
2. 检查`crawled_data/crawler.log`日志文件
3. 启用更详细的日志级别

---

## 📊 数据格式说明

### JSON格式（crawled_data.json）
```json
{
  "title": "页面标题",
  "url": "https://example.com",
  "timestamp": "2024-01-01T12:00:00",
  "content_preview": "内容预览...",
  "full_content": "完整的文本内容...",
  "word_count": 1500,
  "char_count": 8000,
  "total_links": 25,
  "internal_links": 20,
  "external_links": 5,
  "top_links": ["链接1", "链接2", ...],
  "images": ["图片URL1", "图片URL2", ...]
}
```

### 训练数据格式（training_data.txt）
```
URL: https://example.com
标题: 页面标题
字数: 1500 字
内容:
完整的文本内容...

================================================================================

URL: https://example2.com
标题: 另一个页面
字数: 2000 字
内容:
更多文本内容...
```

### DOCX文档结构
- 封面：AI数据采集报告
- 按页面组织的结构化内容
- 包含标题、URL、采集时间、内容摘要
- 专业的段落格式和分页

---

## 🔒 法律和道德声明

### 使用规范
1. **遵守法律法规**：仅在有合法授权的情况下爬取数据
2. **尊重robots.txt**：自动检测并遵守网站爬取规则
3. **合理使用**：避免对目标网站造成性能影响
4. **版权尊重**：仅爬取允许爬取的内容，尊重知识产权
5. **数据用途**：仅用于合法目的，如学术研究、个人学习

### 合规性特性
- **自动robots.txt检查**：在爬取前自动检查网站政策
- **用户确认**：在可能违规时提示用户确认
- **请求频率控制**：避免过于频繁的请求
- **用户代理标识**：明确标识爬虫身份

### 免责声明
- 使用者需对爬取行为的合法性负全部责任
- 开发者不承担因滥用本工具而产生的法律责任
- 建议在使用前咨询相关法律专业人士
- 请仅在获得授权的情况下爬取网站数据

---

## 📄 许可证

本项目采用 **GNU General Public License v3.0 (GPL-3.0)** 许可证。

### GPL-3.0 许可证要点：
- **自由使用**：任何人都可以免费使用、修改和分发本软件
- **源代码开放**：必须提供修改后的源代码
- **相同许可证**：基于本项目的衍生作品必须采用相同的GPL-3.0许可证
- **版权声明**：必须保留原始的版权声明和许可证

完整的许可证文本请查看项目根目录下的 [LICENSE](LICENSE) 文件。

### 商业使用说明
由于采用GPL-3.0许可证，商业使用是允许的，但必须：
1. 公开任何基于本项目的修改版本的源代码
2. 在衍生作品中明确标注原始版权信息
3. 采用相同的GPL-3.0许可证

---

## 🤝 贡献指南

我们欢迎社区贡献！如果您想改进这个项目：

### 贡献流程
1. Fork本项目
2. 创建功能分支 (`git checkout -b feature/AmazingFeature`)
3. 提交更改 (`git commit -m 'Add some AmazingFeature'`)
4. 推送到分支 (`git push origin feature/AmazingFeature`)
5. 开启Pull Request

### 开发环境设置
```bash
# 创建虚拟环境
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows

# 安装开发依赖
pip install -r requirements.txt
```

### 代码规范
- 遵循PEP 8 Python代码规范
- 添加适当的注释和文档
- 确保向后兼容性
- 进行充分的测试

---

## 🙏 致谢

### 特别感谢
- **张悦-玄曦雪**：项目的概念提出者和灵感来源
- **Deepseek AI**：代码实现和技术支持
- **开源社区**：感谢所有依赖库的维护者

### 使用的开源库
- **PyQt5** - 图形界面框架 (GPL许可证)
- **Requests** - HTTP请求库 (Apache 2.0许可证)
- **BeautifulSoup4** - HTML解析库 (MIT许可证)
- **Selenium** - 浏览器自动化工具 (Apache 2.0许可证)
- **python-docx** - Word文档处理 (MIT许可证)
- **webdriver-manager** - 浏览器驱动管理 (Apache 2.0许可证)

---

## 📞 技术支持

如果您在使用过程中遇到问题：

### 获取帮助的途径
1. **查看文档**：仔细阅读本文档的故障排除部分
2. **检查日志**：查看程序生成的日志文件
3. **社区支持**：在项目Issues页面搜索类似问题
4. **提交问题**：如无法解决，提交新的Issue

### 提交问题时的信息
- 操作系统和Python版本
- 完整的错误信息和堆栈跟踪
- 复现问题的详细步骤
- 相关截图或日志文件

---

## 🚀 未来规划

### 计划中的功能
- [ ] 插件系统支持
- [ ] 更多数据导出格式
- [ ] 高级爬取规则配置
- [ ] 批量爬取任务管理
- [ ] 数据分析和可视化
- [ ] 云同步功能

### 欢迎贡献
如果您有兴趣参与开发，欢迎提交Pull Request或提出功能建议！

---

**道衍AI浏览器 - 智能合规爬虫版**  
*让网页浏览和数据采集变得更简单、更智能！*

*概念提出：张悦-玄曦雪*  
*代码实现：Deepseek AI*  
*许可证：GPL-3.0*  
*版本：2.0 专业版*  
*最后更新：2025年11月4日*
